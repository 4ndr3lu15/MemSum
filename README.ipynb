{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641fd659-a0c7-45b7-a9b4-8c77a38ec408",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MemSum: Extractive Summarization of Long Documents Using Multi-Step Episodic Markov Decision Processes\n",
    "\n",
    "Code for ACL 2022 paper on the topic of long document extractive summarization: [MemSum: Extractive Summarization of Long Documents Using Multi-Step Episodic Markov Decision Processes](https://aclanthology.org/2022.acl-long.450/).\n",
    "\n",
    "## Set Up Environment\n",
    "\n",
    "1. create an Anaconda environment, with a name e.g. memsum\n",
    "   \n",
    "   **Note**: Without further notification, the following commands need to be run in the working directory where this jupyter notebook is located.\n",
    "   ```bash\n",
    "   conda create -n memsum python=3.10\n",
    "   ```\n",
    "2. activate this environment\n",
    "   ```bash\n",
    "   source activate memsum\n",
    "   ```\n",
    "   \n",
    "3. Install pytorch (GPU version). \n",
    "   ```bash\n",
    "   pip install torch torchvision torchaudio\n",
    "   ```\n",
    "4. Install dependencies via pip\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc3fdcd-6328-4dba-a9fd-4dc2b8b0b2e4",
   "metadata": {},
   "source": [
    "## Download Datasets and Pretrained Model Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce461a-8830-4657-8808-5db5929178cd",
   "metadata": {},
   "source": [
    "### Download All Datasets Used in the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904f158d-b32a-418c-8f6f-6f3f3bda0d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import wget\n",
    "\n",
    "for dataset_name in [ \"arxiv\", \"pubmed\", \"gov-report\"]:\n",
    "    print(dataset_name)\n",
    "    os.makedirs( \"data/\"+dataset_name, exist_ok=True )\n",
    "    \n",
    "    ## dataset is stored at huggingface hub\n",
    "    train_dataset_path = f\"https://huggingface.co/datasets/nianlong/long-doc-extractive-summarization-{dataset_name}/resolve/main/train.jsonl\"\n",
    "    val_dataset_path = f\"https://huggingface.co/datasets/nianlong/long-doc-extractive-summarization-{dataset_name}/resolve/main/val.jsonl\"\n",
    "    test_dataset_path = f\"https://huggingface.co/datasets/nianlong/long-doc-extractive-summarization-{dataset_name}/resolve/main/test.jsonl\"\n",
    "    \n",
    "    wget.download( train_dataset_path, out = \"data/\"+dataset_name )\n",
    "    wget.download( val_dataset_path, out = \"data/\"+dataset_name )\n",
    "    wget.download( test_dataset_path, out = \"data/\"+dataset_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df95405-7ed1-4ecb-b8e3-b7a93a69b3c2",
   "metadata": {},
   "source": [
    "### Download Pretrained Model Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586c2a3-185f-42b6-890e-d3fdb35383a4",
   "metadata": {},
   "source": [
    "The trained MemSum model checkpoints are stored on huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8e0592-601d-422b-b589-c65726df2bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "## download the pretrained glove word embedding (200 dimension)\n",
    "snapshot_download('nianlong/memsum-word-embedding', local_dir = \"model/word_embedding\" )\n",
    "\n",
    "## download model checkpoint on the arXiv dataset\n",
    "snapshot_download('nianlong/memsum-arxiv', local_dir = \"model/memsum-arxiv\" )\n",
    "\n",
    "## download model checkpoint on the PubMed dataset\n",
    "snapshot_download('nianlong/memsum-pubmed', local_dir = \"model/memsum-pubmed\" )\n",
    "\n",
    "## download model checkpoint on the Gov-Report dataset\n",
    "snapshot_download('nianlong/memsum-gov-report', local_dir = \"model/memsum-gov-report\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8e4ff-dbbf-4aff-81ce-156a9531eda4",
   "metadata": {},
   "source": [
    "## Testing Pretrained Model on a Given Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f2a6f-b310-4f59-b100-9eaf87c99f1c",
   "metadata": {},
   "source": [
    "For example, the following command test the performance of the full MemSum model. Berfore runing these codes, make sure current working directory is the main directory \"MemSum/\" where the .py file summarizers.py is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a8d87d-a6f0-4286-a4ea-0aa81e96c272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.summarizer import MemSum\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c1e1bd-1b75-4807-8ca0-7c6945f6598a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_cal = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "memsum_arxiv = MemSum(  \"model/memsum-arxiv/model.pt\", \n",
    "                  \"model/word_embedding/vocabulary_200dim.pkl\", \n",
    "                  gpu = 0 ,  max_doc_len = 500  )\n",
    "\n",
    "memsum_pubmed = MemSum(  \"model/memsum-pubmed/model.pt\", \n",
    "                  \"model/word_embedding/vocabulary_200dim.pkl\", \n",
    "                  gpu = 0 ,  max_doc_len = 500  )\n",
    "\n",
    "memsum_gov_report = MemSum(  \"model/memsum-gov-report/model.pt\", \n",
    "                  \"model/word_embedding/vocabulary_200dim.pkl\", \n",
    "                  gpu = 0 ,  max_doc_len = 500  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5895fd77-75dd-471b-a878-15f9599a27c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_corpus_arxiv = [ json.loads(line) for line in open(\"data/arxiv/test.jsonl\") ]\n",
    "test_corpus_pubmed = [ json.loads(line) for line in open(\"data/pubmed/test.jsonl\") ]\n",
    "test_corpus_gov_report = [ json.loads(line) for line in open(\"data/gov-report/test.jsonl\") ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32fcdf7-e529-49a7-823e-7f5fcf344e3c",
   "metadata": {},
   "source": [
    "### Evaluation on ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fbddad-1a3c-4098-b493-c4573a7b4f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate( model, corpus, p_stop, max_extracted_sentences, rouge_cal ):\n",
    "    scores = []\n",
    "    for data in tqdm(corpus):\n",
    "        gold_summary = data[\"summary\"]\n",
    "        extracted_summary = model.extract( [data[\"text\"]], p_stop_thres = p_stop, max_extracted_sentences_per_document = max_extracted_sentences )[0]\n",
    "        \n",
    "        score = rouge_cal.score( \"\\n\".join( gold_summary ), \"\\n\".join(extracted_summary)  )\n",
    "        scores.append( [score[\"rouge1\"].fmeasure, score[\"rouge2\"].fmeasure, score[\"rougeLsum\"].fmeasure ] )\n",
    "    \n",
    "    return np.asarray(scores).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acaf3a49-a503-4b56-9cc6-b3d7c0d912b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 6440/6440 [08:00<00:00, 13.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.47946925, 0.19970128, 0.42075852])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate( memsum_arxiv, test_corpus_arxiv, 0.5, 5, rouge_cal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e62125d-47df-41b7-9258-2b93de29b941",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 6658/6658 [09:22<00:00, 11.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49260137, 0.22916328, 0.44415123])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate( memsum_pubmed, test_corpus_pubmed, 0.6, 7, rouge_cal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c72690-4744-4ea8-b5d6-a867c590c535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 973/973 [04:33<00:00,  3.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59445629, 0.28507926, 0.56677073])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate( memsum_gov_report, test_corpus_gov_report, 0.6, 22, rouge_cal )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef374a4-5ef2-4d20-8443-a69b6832d8fd",
   "metadata": {},
   "source": [
    "### Summarization Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198871b-256c-4ced-833f-eec6c1b65f1d",
   "metadata": {},
   "source": [
    "Given a document with a list of sentences, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c13077-2c5d-48d6-a751-2ce646c0c318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document = test_corpus_pubmed[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7329563-0de4-48be-adc5-a8ab86bc9416",
   "metadata": {},
   "source": [
    "We can summarize this document extractively by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e1d49c-d4a8-4f4c-9ef2-213798562947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['more specifically , we found that pd patients with anxiety were more impaired on the trail making test part b which assessed attentional set - shifting , on both digit span tests which assessed working memory and attention , and to a lesser extent on the logical memory test which assessed memory and new verbal learning compared to pd patients without anxiety . taken together ,',\n",
       " 'this study is the first to directly compare cognition between pd patients with and without anxiety .',\n",
       " 'results from this study showed selective verbal memory deficits in rpd patients with anxiety compared to rpd without anxiety , whereas lpd patients with anxiety had greater attentional / working memory deficits compared to lpd without anxiety .',\n",
       " 'given that research on healthy young adults suggests that anxiety reduces processing capacity and impairs processing efficiency , especially in the central executive and attentional systems of working memory [ 26 , 27 ] , we hypothesized that pd patients with anxiety would show impairments in attentional set - shifting and working memory compared to pd patients without anxiety .',\n",
       " 'the findings confirmed our hypothesis that anxiety negatively influences attentional set - shifting and working memory in pd .',\n",
       " 'seventeen pd patients with anxiety and thirty - three pd patients without anxiety were included in this study ( see table 1 ) .']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_summary = memsum_pubmed.extract( [ document ], \n",
    "                                   p_stop_thres = 0.6, \n",
    "                                   max_extracted_sentences_per_document = 7\n",
    "                                  )[0]\n",
    "extracted_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c246b0-aae0-48b0-97c9-14b57ce72a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c026c7ec-d831-4637-bb68-4224f1e0bb8f",
   "metadata": {},
   "source": [
    "We can also get the indices of the extracted sentences in the original document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe28d36-6206-4237-a6ac-ea03f481a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_summary_batch, extracted_indices_batch = memsum_pubmed.extract( [ document ], \n",
    "                                   p_stop_thres = 0.6, \n",
    "                                   max_extracted_sentences_per_document = 7,\n",
    "                                   return_sentence_position=1\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ddf5ca-ef6b-4bc6-ba43-b112bb56d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['more specifically , we found that pd patients with anxiety were more impaired on the trail making test part b which assessed attentional set - shifting , on both digit span tests which assessed working memory and attention , and to a lesser extent on the logical memory test which assessed memory and new verbal learning compared to pd patients without anxiety . taken together ,',\n",
       " 'this study is the first to directly compare cognition between pd patients with and without anxiety .',\n",
       " 'results from this study showed selective verbal memory deficits in rpd patients with anxiety compared to rpd without anxiety , whereas lpd patients with anxiety had greater attentional / working memory deficits compared to lpd without anxiety .',\n",
       " 'given that research on healthy young adults suggests that anxiety reduces processing capacity and impairs processing efficiency , especially in the central executive and attentional systems of working memory [ 26 , 27 ] , we hypothesized that pd patients with anxiety would show impairments in attentional set - shifting and working memory compared to pd patients without anxiety .',\n",
       " 'the findings confirmed our hypothesis that anxiety negatively influences attentional set - shifting and working memory in pd .',\n",
       " 'seventeen pd patients with anxiety and thirty - three pd patients without anxiety were included in this study ( see table 1 ) .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_summary_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40a217d-ec8c-461a-854f-bfdbba9cb245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 48, 70, 14, 49, 16]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_indices_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a802c-594a-4d01-883e-729d19c3d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4d02b83-6c92-4dca-8a76-44347e3739ec",
   "metadata": {},
   "source": [
    "## Training MemSum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee11ed1-1f13-4253-8c0e-baa665fbcff8",
   "metadata": {},
   "source": [
    "Please refer to the documentation XXX for the complete pipeline of training MemSum on custom dataset.\n",
    "\n",
    "You can also directly run the training pipeline on google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48a800-f7ea-42a6-926c-847804c1c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0fad556-cb07-4e13-bde5-fd46d0840fa6",
   "metadata": {},
   "source": [
    "## Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba5f66-928a-4e15-ada4-9995c6c9321e",
   "metadata": {},
   "source": [
    "### Update 09-02-2023: Released the dataset for human evaluation (comparing MemSum with NeuSum). \n",
    "Data is available in folder human_eval_results/. It recorded the samples we used for human evaluation and records of participants' labelling.\n",
    "\n",
    "Released a colab notebook that contained the interface for conducting human evaluation. This can be used for reproducibility test.\n",
    "\n",
    "Jupyter notebook: [MemSum_Human_Evaluation.ipynb](MemSum_Human_Evaluation.ipynb)\n",
    "\n",
    "Run it on colab: \n",
    "<!-- <a href=\"https://colab.research.google.com/github/nianlonggu/MemSum/blob/main/MemSum_Human_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->\n",
    "\n",
    "![human evaluation interface](images/human_evaluation_interface.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef5817-d635-4c49-b7f2-5d39bd93fc4a",
   "metadata": {},
   "source": [
    "### Update 28-07-2022: Code for obtaining the greedy summary of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7047e316-24d6-45c3-8ae6-5beb87c53484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.utils import greedy_extract\n",
    "import json\n",
    "test_corpus_custom_data = [ json.loads(line) for line in open(\"data/custom_data/test.jsonl\")]\n",
    "example_data = test_corpus_custom_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1b8d05-6e2a-4c49-882d-a3854ef8eacf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'summary'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a7784-e92d-431d-9181-f33d481348fa",
   "metadata": {},
   "source": [
    "We can extract the oracle summary by calling the function greedy_extract and set beamsearch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "647399b1-e2e5-4da8-b1b4-d595053a5db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 13, 41, 24, 31, 0, 3, 48], 0.4563635838327488]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_extract( example_data[\"text\"], example_data[\"summary\"], beamsearch_size = 1 )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb857a6-e063-4981-949a-48fc659ff4e3",
   "metadata": {},
   "source": [
    "Here the first element is a list of sentence indices in the document, the second element is the avarge of Rouge F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e783f84-faac-40bc-a5d6-00e09140dcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "632636c0-6b1e-4294-b29b-7cdbf8e968bd",
   "metadata": {},
   "source": [
    "### References\n",
    "When using our code or models for your application, please cite the following paper:\n",
    "```\n",
    "@inproceedings{gu-etal-2022-memsum,\n",
    "    title = \"{M}em{S}um: Extractive Summarization of Long Documents Using Multi-Step Episodic {M}arkov Decision Processes\",\n",
    "    author = \"Gu, Nianlong  and\n",
    "      Ash, Elliott  and\n",
    "      Hahnloser, Richard\",\n",
    "    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n",
    "    month = may,\n",
    "    year = \"2022\",\n",
    "    address = \"Dublin, Ireland\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2022.acl-long.450\",\n",
    "    pages = \"6507--6522\",\n",
    "    abstract = \"We introduce MemSum (Multi-step Episodic Markov decision process extractive SUMmarizer), a reinforcement-learning-based extractive summarizer enriched at each step with information on the current extraction history. When MemSum iteratively selects sentences into the summary, it considers a broad information set that would intuitively also be used by humans in this task: 1) the text content of the sentence, 2) the global text context of the rest of the document, and 3) the extraction history consisting of the set of sentences that have already been extracted. With a lightweight architecture, MemSum obtains state-of-the-art test-set performance (ROUGE) in summarizing long documents taken from PubMed, arXiv, and GovReport. Ablation studies demonstrate the importance of local, global, and history information. A human evaluation confirms the high quality and low redundancy of the generated summaries, stemming from MemSum{'}s awareness of extraction history.\",\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:memsum]",
   "language": "python",
   "name": "conda-env-memsum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
