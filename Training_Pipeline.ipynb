{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a0fab8-62db-474d-8fd8-6f8a230e8778",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842d787-7479-4fee-9c21-b595f2e5b75f",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761cb3f5-6016-40a3-a93e-a9944b4d8741",
   "metadata": {},
   "source": [
    "1. create an Anaconda environment, with a name e.g. memsum\n",
    "   \n",
    "   **Note**: Without further notification, the following commands need to be run in the working directory where this jupyter notebook is located.\n",
    "   ```bash\n",
    "   conda create -n memsum python=3.10\n",
    "   ```\n",
    "2. activate this environment\n",
    "   ```bash\n",
    "   source activate memsum\n",
    "   ```\n",
    "   \n",
    "3. Install pytorch (GPU version). \n",
    "   ```bash\n",
    "   pip install torch torchvision torchaudio\n",
    "   ```\n",
    "4. Install dependencies via pip\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "   \n",
    "Note: If you are runing this notebook on google Colab with GPU runtime, step 1 and 2 are not needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1d147-6668-4710-a987-bbd6388111fd",
   "metadata": {},
   "source": [
    "# Preprocessing Custom data\n",
    "\n",
    "Suppose that you have already splitted the training / validation and  test set:\n",
    "\n",
    "The training data is now stored in a .jsonl file that contains a list of json info, one line for one training instance. Each json (or dictonary) contains two keys: \n",
    "\n",
    "1. \"text\": the value for which is a python list of sentences, this represents the document you want to summarize;\n",
    "2. \"summary\": the value is also a list of sentences. If represent the ground-truth summary. Because the summary can contain multiple sentences, so we store them as a list.\n",
    "\n",
    "The same for the validation file and the testing file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4feeaa6b-c69c-4aaa-8c6b-b3ad02516cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "dict_keys(['text', 'summary'])\n",
      "['a recent systematic analysis showed that in 2011 , 314 ( 296 - 331 ) million children younger than 5 years were mildly , moderately or severely stunted and 258 ( 240 - 274 ) million were mildly , moderately or severely underweight in the developing countries .', 'in iran a study among 752 high school girls in sistan and baluchestan showed prevalence of 16.2% , 8.6% and 1.5% , for underweight , overweight and obesity , respectively .', 'the prevalence of malnutrition among elementary school aged children in tehran varied from 6% to 16% .']\n",
      "['background : the present study was carried out to assess the effects of community nutrition intervention based on advocacy approach on malnutrition status among school - aged children in shiraz , iran.materials and methods : this case - control nutritional intervention has been done between 2008 and 2009 on 2897 primary and secondary school boys and girls ( 7 - 13 years old ) based on advocacy approach in shiraz , iran .', 'the project provided nutritious snacks in public schools over a 2-year period along with advocacy oriented actions in order to implement and promote nutritional intervention . for evaluation of effectiveness of the intervention growth monitoring indices of pre- and post - intervention were statistically compared.results:the frequency of subjects with body mass index lower than 5% decreased significantly after intervention among girls ( p = 0.02 ) .', 'however , there were no significant changes among boys or total population .']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "train_corpus = [ json.loads(line) for line in open(\"data/custom_data/train_raw_without_high_rouge_indices_and_scores.jsonl\") ]\n",
    "\n",
    "## as an example, we have 100 instances for training\n",
    "print(len(train_corpus))\n",
    "print(train_corpus[0].keys())\n",
    "print(train_corpus[0][\"text\"][:3])\n",
    "print(train_corpus[0][\"summary\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb0ec6-3ede-4687-9565-7cb1b4c0872e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4c8ff7e-8b6e-4250-aaf8-bd73f828ad78",
   "metadata": {},
   "source": [
    "If you have your own data, process them into the same structure then put them into the data/ folder\n",
    "\n",
    "The next thing we need to do is to create high-ROUGE episodes for the training set, as introduced in the paper: https://aclanthology.org/2022.acl-long.450/:\n",
    "\n",
    "Note: The '!' in the following commands is only needed when running shell command in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b178ac-1fda-4f2a-a1c5-1c290d5ee810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70it [00:06, 11.10it/s]]\n",
      "finished!\n",
      "30it [00:06,  4.53it/s]\n",
      "finished!\n",
      "50it [00:06,  7.45it/s]\n",
      "finished!\n",
      "90it [00:06, 13.23it/s] \n",
      "finished!\n",
      "10it [00:07,  1.38it/s]\n",
      "finished!\n",
      "20it [00:07,  2.53it/s]\n",
      "finished!\n",
      "40it [00:07,  5.01it/s]\n",
      "finished!\n",
      "80it [00:08,  9.94it/s]\n",
      "finished!\n",
      "60it [00:08,  7.35it/s]\n",
      "finished!\n",
      "100it [00:08, 11.28it/s]\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "!cd data_preprocessing; python get_high_rouge_episodes_mp.py -input_corpus_file_name ../data/custom_data/train_raw_without_high_rouge_indices_and_scores.jsonl -output_corpus_file_name ../data/custom_data/train.jsonl -beamsearch_size 2 -n_processes 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18aae5-d2cc-4724-81ee-04e472d6b887",
   "metadata": {},
   "source": [
    "# Download pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35d5711-603b-4198-8531-3fa52d2d2b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "## download the pretrained glove word embedding (200 dimension)\n",
    "snapshot_download('nianlong/memsum-word-embedding', local_dir = \"model/word_embedding\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a94a2-d7ec-4ca4-804b-e8acf630bb48",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a904552-16a6-4c6b-ba57-322c9f142b56",
   "metadata": {},
   "source": [
    "Note:\n",
    "1. you need to switch to the folder src/MemSum_Full;\n",
    "2. You can specify the path to training and validation set, the model_folder (where you want to store model checkpoints) and the log_folder (where you want to store the log info), and other parameters. \n",
    "3. You can provide the absolute path, or relative path, as shown in the example code below.\n",
    "4. n_device means the number of available GPUs\n",
    "5. set save_every and validate_every to 0 will make the training script save and evaluate the model only at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b043ab53-ba52-4b49-bf19-8ad6952796b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100it [00:00, 15554.62it/s]\n",
      "100it [00:00, 19677.71it/s]\n",
      "24it [00:11,  2.16it/s]Starting validation ...\n",
      "[current_batch: 00025] val: 0.0000, 0.0000, 0.0000\n",
      "25it [00:15,  1.58it/s]\n",
      "24it [00:11,  2.15it/s]Starting validation ...\n",
      "[current_batch: 00050] val: 0.3731, 0.1170, 0.3347\n",
      "25it [00:18,  1.36it/s]\n",
      "24it [00:11,  2.15it/s]Starting validation ...\n",
      "[current_batch: 00075] val: 0.3766, 0.1242, 0.3382\n",
      "25it [00:18,  1.37it/s]\n",
      "24it [00:11,  2.14it/s][current_batch: 00100] loss: 0.508, learning rate: 0.000100\n",
      "Starting validation ...\n",
      "[current_batch: 00100] val: 0.3781, 0.1259, 0.3404\n",
      "25it [00:18,  1.35it/s]\n",
      "24it [00:11,  2.12it/s]Starting validation ...\n",
      "[current_batch: 00125] val: 0.3731, 0.1225, 0.3356\n",
      "25it [00:18,  1.36it/s]\n",
      "24it [00:11,  2.13it/s]Starting validation ...\n",
      "[current_batch: 00150] val: 0.3717, 0.1225, 0.3351\n",
      "25it [00:18,  1.36it/s]\n",
      "24it [00:11,  2.14it/s]Starting validation ...\n",
      "[current_batch: 00175] val: 0.3789, 0.1303, 0.3415\n",
      "25it [00:18,  1.35it/s]\n",
      "24it [00:11,  2.13it/s][current_batch: 00200] loss: 0.503, learning rate: 0.000100\n",
      "Starting validation ...\n",
      "[current_batch: 00200] val: 0.3803, 0.1305, 0.3420\n",
      "25it [00:18,  1.35it/s]\n",
      "24it [00:11,  2.12it/s]Starting validation ...\n",
      "[current_batch: 00225] val: 0.3792, 0.1286, 0.3395\n",
      "25it [00:18,  1.35it/s]\n",
      "24it [00:11,  2.14it/s]Starting validation ...\n",
      "[current_batch: 00250] val: 0.3796, 0.1304, 0.3409\n",
      "25it [00:18,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "!cd src; python train.py -training_corpus_file_name ../data/custom_data/train.jsonl -validation_corpus_file_name ../data/custom_data/val.jsonl -model_folder ../model/memsum-custom-data -log_folder ../log/memsum-custom-data -vocabulary_file_name ../model/word_embedding/vocabulary_200dim.pkl -pretrained_unigram_embeddings_file_name ../model/word_embedding/unigram_embeddings_200dim.pkl -max_seq_len 100 -max_doc_len 500 -num_of_epochs 10 -save_every 0 -validate_every 0 -n_device 1 -batch_size_per_device 4 -max_extracted_sentences_per_document 7 -moving_average_decay 0.999 -p_stop_thres 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587187c-6de9-4141-a64f-ce4dfeb45754",
   "metadata": {},
   "source": [
    "# Determine the best checkpoint based on validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed467c81-cec8-461d-9f9c-f885ad367b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 200 scores: ('0.3803', '0.1305', '0.3420')\n"
     ]
    }
   ],
   "source": [
    "! cd src; python get_optimal_batch.py -log_file_name ../log/memsum-custom-data/val.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106b953-9da2-4802-8ddb-242fd36b889e",
   "metadata": {},
   "source": [
    "So the best checkpoint is model_batch_200.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d02ea-f540-4bc7-b1d1-bc6c6043fa88",
   "metadata": {},
   "source": [
    "# Testing trained model on custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef65c109-2f50-4284-ab86-6ca2c5471c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.summarizer import MemSum\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a2b5ad-e37e-4ab5-9176-b1eca64bcb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_cal = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "memsum_custom_data = MemSum(  \"model/memsum-custom-data/model_batch_200.pt\", \n",
    "                  \"model/word_embedding/vocabulary_200dim.pkl\", \n",
    "                  gpu = 0 ,  max_doc_len = 500  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a365fbe7-c196-4789-8c5c-177f39cd88c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_corpus_custom_data = [ json.loads(line) for line in open(\"data/custom_data/test.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d796f58-0d37-47fb-b13c-985b944a0073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate( model, corpus, p_stop, max_extracted_sentences, rouge_cal ):\n",
    "    scores = []\n",
    "    for data in tqdm(corpus):\n",
    "        gold_summary = data[\"summary\"]\n",
    "        extracted_summary = model.extract( [data[\"text\"]], p_stop_thres = p_stop, max_extracted_sentences_per_document = max_extracted_sentences )[0]\n",
    "        \n",
    "        score = rouge_cal.score( \"\\n\".join( gold_summary ), \"\\n\".join(extracted_summary)  )\n",
    "        scores.append( [score[\"rouge1\"].fmeasure, score[\"rouge2\"].fmeasure, score[\"rougeLsum\"].fmeasure ] )\n",
    "    \n",
    "    return np.asarray(scores).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "878d74d5-c096-40ef-a7e9-3f5db267ef11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.40608886, 0.14885996, 0.36723294])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate( memsum_custom_data, test_corpus_custom_data, 0.6, 7, rouge_cal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779a6df-8387-4c88-a380-579feb42e81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b9b7f7-1b29-4fd7-af68-4a3bc3d9844d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male macroprolactinomas ( mprl ) are usually revealed by headaches , visual troubles and gonadal insufficiency .',\n",
       " 'suppurative meningitis ( sm ) , a life - threatening condition , is scarcely observed in subjects with macro tumors secreting prolactin ( prl ) and in other pituitary tumors ( pt ) .',\n",
       " 'however , in some very rare cases it can be a primary presentation or appear after radiotherapy or medical treatment used for tumors destroying the sellar floor and/or the skull base .',\n",
       " 'our aim was to analyze sm frequency among male mprl deemed to be very invasive tumors , to report our cases and analyze the circumstances under which the dangerous neurological complication appeared .',\n",
       " 'this destruction leads to cerebral spinal fluid ( csf ) leak , which can act as an entry portal for organisms predisposing to meningitis .',\n",
       " 'in this retrospective study , we analyzed 82 subjects with mprl to look for symptoms , clinical signs and biological proof of sm .',\n",
       " 'the described cases emphasize the necessity of an early diagnosis and treatment of large and invasive pt , especially male mprl . medical treatment , which is now the gold standard for prolactinomas ,']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = test_corpus_custom_data[10][\"text\"]\n",
    "extracted_summary = memsum_custom_data.extract( [ document ], \n",
    "                                   p_stop_thres = 0.6, \n",
    "                                   max_extracted_sentences_per_document = 7\n",
    "                                  )[0]\n",
    "extracted_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdccce-4f3c-4c6f-a771-ee8fdd92f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96e5c7-9b2b-40ce-b764-7c9b819e810f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:memsum]",
   "language": "python",
   "name": "conda-env-memsum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
